{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importing libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import xgboost as xgb\n",
    "import lightgbm as lgb\n",
    "import catboost as cat\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "from sklearn.ensemble import VotingClassifier\n",
    "from sklearn.model_selection import GridSearchCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Helper function\n",
    "def to_datetime(df):\n",
    "    df['match_dt'] = pd.to_datetime(df['match_dt'], format='%Y-%m-%d')\n",
    "    return df\n",
    "\n",
    "def rm_blankspace(df):\n",
    "    df.rename(columns=lambda x: x.replace(' ', '_'), inplace=True)\n",
    "    return df\n",
    "\n",
    "def unwrap_rosters(df):\n",
    "    df['team1_roster_ids'] = df['team1_roster_ids'].apply(lambda x: x.split(':'))\n",
    "    df['team2_roster_ids'] = df['team2_roster_ids'].apply(lambda x: x.split(':'))\n",
    "    return df\n",
    "\n",
    "def data_preprocessing(df):\n",
    "    df = to_datetime(df)\n",
    "    df = rm_blankspace(df)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importing datset\n",
    "train_data = pd.read_csv('data//train_data.csv',)\n",
    "\n",
    "batsman_data = pd.read_csv('data//batsman_level_data.csv')\n",
    "\n",
    "bowler_data = pd.read_csv('data//bowler_level_data.csv')\n",
    "\n",
    "match_data = pd.read_csv('data//match_level_data.csv')\n",
    "\n",
    "test_data = pd.read_csv('data//round_1_sub_data.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = data_preprocessing(train_data)\n",
    "train_data = unwrap_rosters(train_data)\n",
    "match_data = data_preprocessing(match_data)\n",
    "match_data = unwrap_rosters(match_data)\n",
    "test_data = data_preprocessing(test_data)\n",
    "test_data = unwrap_rosters(test_data)\n",
    "\n",
    "batsman_data = data_preprocessing(batsman_data)\n",
    "bowler_data = data_preprocessing(bowler_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reordering columns\n",
    "match_data['toss_winner_id'] = np.where(match_data['toss_winner'] == match_data['team1'], match_data['team1_id'], match_data['team2_id'])\n",
    "match_data = match_data[['match_id', 'match_dt', 'team1', 'team1_id', 'team2', 'team2_id',\n",
    "        'toss_winner_id', 'toss_decision', 'ground_id', 'lighting', 'series_name',\n",
    "        'winner_id', 'by', 'win_amount', 'player_of_the_match_id',\n",
    "        'inning1_runs', 'inning1_wickets', 'inning1_balls', 'inning2_runs', 'inning2_wickets', 'inning2_balls',\n",
    "        'team1_roster_ids', 'team2_roster_ids']]\n",
    "\n",
    "train_data['toss_winner_id'] = np.where(train_data['toss_winner'] == train_data['team1'], train_data['team1_id'], train_data['team2_id'])\n",
    "train_data = train_data[['match_id', 'match_dt', 'team1', 'team1_id', 'team2', 'team2_id',\n",
    "       'toss_winner', 'toss_decision', 'ground_id', 'lighting', 'series_name',\n",
    "       'winner_id', 'team1_roster_ids', 'team2_roster_ids', 'team_count_50runs_last15',\n",
    "       'team_winp_last5', 'team1only_avg_runs_last15', 'team1_winp_team2_last15','ground_avg_runs_last15']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cheatsheet features\n",
    "def giveLastNgamesPlayer(player_id, date, n, bat_or_bowl):\n",
    "    '''\n",
    "    Function to get last n games stats of a player before an input date.\n",
    "    \n",
    "    Input-\n",
    "    1. player_id: id of the player to get historical data.\n",
    "    2. date: date to look-back and get n games. Stats returned are before this input date.\n",
    "    3. n: Number of historical games stats to return.\n",
    "    4. bat_or_bowl: Kind of stats to return. {'bat': batting stats to return, 'bowl': bowling stats to return}\n",
    "    '''\n",
    "    if bat_or_bowl == 'bat':\n",
    "        df_topick = batsman_data\n",
    "        id_col = 'batsman_id'\n",
    "    else:\n",
    "        df_topick = bowler_data\n",
    "        id_col = 'bowler_id'\n",
    "        \n",
    "    return df_topick[(df_topick['match_dt']<date)&(df_topick[id_col]==float(player_id))]\\\n",
    "                .sort_values(by='match_dt', ascending=False).head(n)\n",
    "\n",
    "def no50sLastn(player_list, date, n):\n",
    "    '''\n",
    "    Function to get total number of 50s scored by players in the roster of a team in last n games.\n",
    "    \n",
    "    Input-\n",
    "    1. player_list: ':' separated list of player ids in the roster of a team.\n",
    "    2. date: match date of the game to calculate this feature.\n",
    "    3. n: Number of games to look-back and create this feature.\n",
    "    \n",
    "    '''\n",
    "    res_list = []\n",
    "    for player in player_list:\n",
    "        df_rel = giveLastNgamesPlayer(player_id=player, date=date, n=n, bat_or_bowl='bat')\n",
    "        df_rel['gte_50runs'] = np.where(df_rel['runs']>=50, 1, 0)\n",
    "        res_list.append(np.nansum(df_rel['gte_50runs']))\n",
    "    return np.nansum(res_list)\n",
    "\n",
    "def avgRunsGround(ground_id, date, n):\n",
    "    '''\n",
    "    Function to calculate average runs scored in ground/venue.\n",
    "    \n",
    "    Input-\n",
    "    1. ground_id: ID of the ground to calculate the feature for.\n",
    "    2. date: match date of the current game to calculate the feature for.\n",
    "    3. n: look-back window of games for the ground.\n",
    "    '''\n",
    "\n",
    "    df_rel = match_data[(match_data['match_dt']<date)&(match_data['ground_id']==ground_id)].sort_values(by='match_dt', ascending=False).head(n)\n",
    "    df_rel['avg_runs_inn'] = (df_rel['inning1_runs']+df_rel['inning2_runs'])/2\n",
    "    return df_rel['avg_runs_inn'].mean()\n",
    "\n",
    "def teamAvgRunsLastn(team_id, date, n):\n",
    "    '''\n",
    "    Function to calculate a team's average runs in their last n games.\n",
    "    \n",
    "    Input-\n",
    "    1. team_id: ID of the team to calculate average runs.\n",
    "    2. date: match date of the current game for which the feature is calculated.\n",
    "    3. n: look-back window of games for the team.\n",
    "    '''\n",
    "    match_data['team1_bat_inning'] = np.where( ((match_data['team1']==match_data['toss winner'])&(match_data['toss decision']=='bat'))|\\\n",
    "                                               ((match_data['team2']==match_data['toss winner'])&(match_data['toss decision']=='field')) , 1, 2)\n",
    "\n",
    "    df_rel = match_data[(match_data['match_dt']<date)&\\\n",
    "                      ((match_data['team1_id']==team_id)|(match_data['team2_id']==team_id))]\\\n",
    "                        .sort_values(by='match_dt', ascending=False).head(n)\n",
    "    \n",
    "    df_rel = pd.concat([ df_rel[df_rel['team1_bat_inning']==1][['inning1_runs']].rename(columns={'inning1_runs':'runs'}), \\\n",
    "                         df_rel[df_rel['team1_bat_inning']==2][['inning2_runs']].rename(columns={'inning2_runs':'runs'}) ] )\n",
    "    return df_rel['runs'].mean()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ratio agnostic features\n",
    "def tossWinnerWins(team1_id, team2_id, date):\n",
    "    '''\n",
    "    Function to compute percent of games toss winner wins the game.\n",
    "    \n",
    "    Input-\n",
    "    1. team1_id: ID of team1\n",
    "    2. team2_id: ID of team2\n",
    "    3: date: match date of the current game for which the feature is to be calculated.\n",
    "    '''\n",
    "    match_data['DtossWinnerWins'] = np.where(match_data['toss_winner_id'] == match_data['winner_id'], 1, 0)\n",
    "    df_rel = match_data[(match_data['match_dt']<date)&\\\n",
    "                        (((match_data['team1_id']==team1_id)&(match_data['team2_id']==team2_id))|\\\n",
    "                         ((match_data['team1_id']==team2_id)&(match_data['team2_id']==team1_id)))]\\\n",
    "                        .sort_values(by='match_dt', ascending=False)\n",
    "    \n",
    "    res = df_rel['DtossWinnerWins'].values\n",
    "    if len(res)==0:\n",
    "        return 0.5\n",
    "    else:\n",
    "        return round(np.mean(df_rel['DtossWinnerWins'].values),2)\n",
    "\n",
    "def teamBatsFirstWins(team1_id, team2_id, date):\n",
    "    '''\n",
    "    Function to compute percent of games team that bats first wins the game.\n",
    "    \n",
    "    Input-\n",
    "    1. team1_id: ID of team1\n",
    "    2. team2_id: ID of team2\n",
    "    3: date: match date of the current game for which the feature is to be calculated.\n",
    "    '''\n",
    "    match_data['toss_decision_bats'] = np.where(match_data['toss_decision'] == 'bat', 1, 0)\n",
    "\n",
    "    match_data['DteamBatsFirstWins'] = np.where(((match_data['DtossWinnerWins'] == 1) & (match_data['toss_decision_bats'] == 1))\n",
    "                                          | ((match_data['DtossWinnerWins'] == 0) & (match_data['toss_decision_bats'] == 0)), 1, 0)\n",
    "  \n",
    "    df_rel = match_data[(match_data['match_dt']<date)&\\\n",
    "                        (((match_data['team1_id']==team1_id)&(match_data['team2_id']==team2_id))|\\\n",
    "                         ((match_data['team1_id']==team2_id)&(match_data['team2_id']==team1_id)))]\\\n",
    "                        .sort_values(by='match_dt', ascending=False)\n",
    "\n",
    "    res = df_rel['DteamBatsFirstWins'].values\n",
    "    if len(res)==0:\n",
    "        return 0.5\n",
    "    else:\n",
    "        return round(np.mean(df_rel['DteamBatsFirstWins'].values),2)\n",
    "\n",
    "def teamBatsFirstWinsAtGround(team1_id, team2_id, date, ground):\n",
    "    '''\n",
    "    Function to compute percent of games team that bats first wins the game.\n",
    "    \n",
    "    Input-\n",
    "    1. team1_id: ID of team1\n",
    "    2. team2_id: ID of team2\n",
    "    3: date: match date of the current game for which the feature is to be calculated.\n",
    "    4. ground: Ground ID of the current game.\n",
    "    '''\n",
    "\n",
    "    df_rel = match_data[(match_data['match_dt']<date)&\\\n",
    "                        (match_data['ground_id'] == ground)&\\\n",
    "                        (((match_data['team1_id']==team1_id)&(match_data['team2_id']==team2_id))|\\\n",
    "                         ((match_data['team1_id']==team2_id)&(match_data['team2_id']==team1_id)))]\\\n",
    "                        .sort_values(by='match_dt', ascending=False)\n",
    "\n",
    "    res = df_rel['DteamBatsFirstWins'].values\n",
    "    if len(res)==0:\n",
    "        return 0.5\n",
    "    else:\n",
    "        return round(np.mean(df_rel['DteamBatsFirstWins'].values),2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ratio agnostic features\n",
    "\n",
    "# tossWinnerWins\n",
    "train_data['tossWinnerWins'] = train_data.apply(lambda x: tossWinnerWins(x['team1_id'], x['team2_id'], x['match_dt']), axis=1)\n",
    "test_data['tossWinnerWins'] = test_data.apply(lambda x: tossWinnerWins(x['team1_id'], x['team2_id'], x['match_dt']), axis=1)\n",
    "\n",
    "# teamBatsFirstWins\n",
    "train_data['teamBatsFirstWins'] = train_data.apply(lambda x: teamBatsFirstWins(x['team1_id'], x['team2_id'], x['match_dt']), axis=1)\n",
    "test_data['teamBatsFirstWins'] = test_data.apply(lambda x: teamBatsFirstWins(x['team1_id'], x['team2_id'], x['match_dt']), axis=1)\n",
    "\n",
    "# teamBatsFirstWins\n",
    "train_data['teamBatsFirstWinsAtGround'] = train_data.apply(lambda x: teamBatsFirstWinsAtGround(x['team1_id'], x['team2_id'], x['match_dt'],x['ground_id']), axis=1)\n",
    "test_data['teamBatsFirstWinsAtGround'] = test_data.apply(lambda x: teamBatsFirstWinsAtGround(x['team1_id'], x['team2_id'], x['match_dt'],x['ground_id']), axis=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Team1 to Team2 ratio features\n",
    "def team1WinpAtGround(team1_id, team2_id, date, ground):\n",
    "    '''\n",
    "    Function to compute team1's win% against team2 from the current game at the given ground.\n",
    "    \n",
    "    Input-\n",
    "    1. team1_id: ID of team1 to calculate win% of.\n",
    "    2. team2_id: ID of team2 to calculate win% against.\n",
    "    3: date: match date of the current game for which the feature is to be calculated.\n",
    "    4. ground: Ground ID of the current game.\n",
    "    '''\n",
    "\n",
    "    df_rel = match_data[(match_data['match_dt']<date)&\\\n",
    "                        (match_data['ground_id'] == ground)&\\\n",
    "                      (((match_data['team1_id']==team1_id)&(match_data['team2_id']==team2_id))|\\\n",
    "                       ((match_data['team1_id']==team2_id)&(match_data['team2_id']==team1_id)))]\\\n",
    "                        .sort_values(by='match_dt', ascending=False)\n",
    "\n",
    "    \n",
    "    if len(df_rel) == 0:\n",
    "        return 0.5\n",
    "    else:\n",
    "        win_count = df_rel[df_rel['winner_id']==team1_id].shape[0]\n",
    "        return round(win_count/df_rel.shape[0], 2)\n",
    "\n",
    "def team1WinpLight(team1_id, team2_id, date, light):\n",
    "    '''\n",
    "    Function to compute team1's win% against team2 from the current game at the given lighting.\n",
    "    \n",
    "    Input-\n",
    "    1. team1_id: ID of team1 to calculate win% of.\n",
    "    2. team2_id: ID of team2 to calculate win% against.\n",
    "    3: date: match date of the current game for which the feature is to be calculated.\n",
    "    4. light: Lighting condition of the current game.\n",
    "    '''\n",
    "\n",
    "    df_rel = match_data[(match_data['match_dt']<date)&\\\n",
    "                        (match_data['lighting'] == light)&\\\n",
    "                      (((match_data['team1_id']==team1_id)&(match_data['team2_id']==team2_id))|\\\n",
    "                       ((match_data['team1_id']==team2_id)&(match_data['team2_id']==team1_id)))]\\\n",
    "                        .sort_values(by='match_dt', ascending=False)\n",
    "\n",
    "    if len(df_rel) == 0:\n",
    "        return 0.5\n",
    "    else:\n",
    "        win_count = df_rel[df_rel['winner_id']==team1_id].shape[0]\n",
    "        return round(win_count/df_rel.shape[0], 2)\n",
    "\n",
    "def team1WinpSeries(team1_id, team2_id, date, series):\n",
    "    '''\n",
    "    Function to compute team1's win% against team2 from the current game at the given lighting.\n",
    "    \n",
    "    Input-\n",
    "    1. team1_id: ID of team1 to calculate win% of.\n",
    "    2. team2_id: ID of team2 to calculate win% against.\n",
    "    3: date: match date of the current game for which the feature is to be calculated.\n",
    "    4. series: Series name of the current game.\n",
    "    '''\n",
    "\n",
    "    df_rel = match_data[(match_data['match_dt']<date)&\\\n",
    "                        (match_data['series_name'] == series)&\\\n",
    "                      (((match_data['team1_id']==team1_id)&(match_data['team2_id']==team2_id))|\\\n",
    "                       ((match_data['team1_id']==team2_id)&(match_data['team2_id']==team1_id)))]\\\n",
    "                        .sort_values(by='match_dt', ascending=False)\n",
    "\n",
    "    if len(df_rel) == 0:\n",
    "        return 0.5\n",
    "    else:\n",
    "        win_count = df_rel[df_rel['winner_id']==team1_id].shape[0]\n",
    "        return round(win_count/df_rel.shape[0], 2)\n",
    "\n",
    "def team1AvgRunsMargin(team1_id, team2_id, date, n):\n",
    "    '''\n",
    "    Function to calculate ratio of team1's average runs margin against team2 in last n games.\n",
    "    \n",
    "    Input-\n",
    "    1. team1_id: ID of team1 to calculate average runs margin.\n",
    "    2. team2_id: ID of team2 to calculate average runs margin against.\n",
    "    3: date: match date of the current game for which the feature is to be calculated.\n",
    "    4. n: look-back window of games for the team.\n",
    "    '''\n",
    "    df_rel1 = match_data[(match_data['match_dt']<date)&\\\n",
    "                      ((match_data['team1_id']==team1_id)|(match_data['team2_id']==team1_id))&\\\n",
    "                       (match_data['winner_id']==team1_id)&\\\n",
    "                        (match_data['by']=='runs')]\\\n",
    "                        .sort_values(by='match_dt', ascending=False).head(n)\n",
    "    \n",
    "    df_rel2 = match_data[(match_data['match_dt']<date)&\\\n",
    "                      ((match_data['team1_id']==team2_id)|(match_data['team2_id']==team2_id))&\\\n",
    "                       (match_data['winner_id']==team2_id)&\\\n",
    "                        (match_data['by']=='runs')]\\\n",
    "                        .sort_values(by='match_dt', ascending=False).head(n)\n",
    "\n",
    "    if len(df_rel1)==0 or len(df_rel2)==0:\n",
    "        return 1\n",
    "    else:\n",
    "        return np.mean(df_rel1['win_amount'])/np.mean(df_rel2['win_amount'])\n",
    "    \n",
    "def team1AvgWicketsMargin(team1_id, team2_id, date, n):\n",
    "    '''\n",
    "    Function to calculate team1's average wickets margin against team2 in last n games.\n",
    "    \n",
    "    Input-\n",
    "    1. team1_id: ID of team1 to calculate average runs margin.\n",
    "    2. team2_id: ID of team2 to calculate average runs margin against.\n",
    "    3: date: match date of the current game for which the feature is to be calculated.\n",
    "    4. n: look-back window of games for the team.\n",
    "    '''\n",
    "    df_rel1 = match_data[(match_data['match_dt']<date)&\\\n",
    "                      ((match_data['team1_id']==team1_id)|(match_data['team2_id']==team1_id))&\\\n",
    "                       (match_data['winner_id']==team1_id)&\\\n",
    "                        (match_data['by']=='wickets')]\\\n",
    "                        .sort_values(by='match_dt', ascending=False).head(n)\n",
    "    \n",
    "    df_rel2 = match_data[(match_data['match_dt']<date)&\\\n",
    "                      ((match_data['team1_id']==team2_id)|(match_data['team2_id']==team2_id))&\\\n",
    "                       (match_data['winner_id']==team2_id)&\\\n",
    "                        (match_data['by']=='wickets')]\\\n",
    "                        .sort_values(by='match_dt', ascending=False).head(n)\n",
    "\n",
    "    if len(df_rel1)==0 or len(df_rel2)==0:\n",
    "        return 1\n",
    "    else:\n",
    "        return np.mean(df_rel1['win_amount'])/np.mean(df_rel2['win_amount'])\n",
    "\n",
    "def team1AvgWicketsLost(team1_id, team2_id, date, n):\n",
    "    '''\n",
    "    Function to calculate team1's average wickets lost per balls against team2 in last n games.\n",
    "    \n",
    "    Input-\n",
    "    1. team1_id: ID of team1 to calculate average wickets lost.\n",
    "    2. team2_id: ID of team2 to calculate average wickets lost against.\n",
    "    3: date: match date of the current game for which the feature is to be calculated.\n",
    "    4. n: look-back window of games for the team.\n",
    "    '''\n",
    "    df_rel1 = match_data[(match_data['match_dt']<date)&\\\n",
    "                      ((match_data['team1_id']==team1_id)|(match_data['team2_id']==team1_id))]\\\n",
    "                        .sort_values(by='match_dt', ascending=False).head(n)\n",
    "\n",
    "    df_rel2 = match_data[(match_data['match_dt']<date)&\\\n",
    "                      ((match_data['team1_id']==team2_id)|(match_data['team2_id']==team2_id))]\\\n",
    "                        .sort_values(by='match_dt', ascending=False).head(n)\n",
    "\n",
    "    df_rel1['bat_inning'] = np.where( ((df_rel1['team1_id']==df_rel1['toss_winner_id'])&(df_rel1['toss_decision']=='bat'))|\\\n",
    "                                            ((df_rel1['team2_id']==df_rel1['toss_winner_id'])&(df_rel1['toss_decision']=='field')) , 1, 2)\n",
    "\n",
    "    df_rel2['bat_inning'] = np.where( ((df_rel2['team1_id']==df_rel2['toss_winner_id'])&(df_rel2['toss_decision']=='bat'))|\\\n",
    "                                            ((df_rel2['team2_id']==df_rel2['toss_winner_id'])&(df_rel2['toss_decision']=='field')) , 1, 2)\n",
    "    \n",
    "    df_rel1 = df_rel1[df_rel1['bat_inning']==1][['inning1_wickets', 'inning1_balls']].rename(columns={'inning1_wickets':'wickets', 'inning1_balls':'balls'})\n",
    "    df_rel2 = df_rel2[df_rel2['bat_inning']==1][['inning1_wickets', 'inning1_balls']].rename(columns={'inning1_wickets':'wickets', 'inning1_balls':'balls'})\n",
    "    df_rel1['ball_per_wick'] = df_rel1['balls']/(df_rel1['wickets']+1)\n",
    "    df_rel2['ball_per_wick'] = df_rel2['balls']/(df_rel2['wickets']+1)\n",
    "\n",
    "    if len(df_rel1)==0 or len(df_rel2)==0:\n",
    "        return 1\n",
    "    else:\n",
    "        return df_rel1['ball_per_wick'].mean()/df_rel2['ball_per_wick'].mean()\n",
    "\n",
    "def team1AvgRR(team1_id, team2_id, date, n):\n",
    "    '''\n",
    "    Function to calculate team1's average run rate against team2 in last n games.\n",
    "    \n",
    "    Input-\n",
    "    1. team1_id: ID of team1 to calculate average wickets lost.\n",
    "    2. team2_id: ID of team2 to calculate average wickets lost against.\n",
    "    3: date: match date of the current game for which the feature is to be calculated.\n",
    "    4. n: look-back window of games for the team.\n",
    "    '''\n",
    "    df_rel1 = match_data[(match_data['match_dt']<date)&\\\n",
    "                      ((match_data['team1_id']==team1_id)|(match_data['team2_id']==team1_id))]\\\n",
    "                        .sort_values(by='match_dt', ascending=False).head(n)\n",
    "\n",
    "    df_rel2 = match_data[(match_data['match_dt']<date)&\\\n",
    "                      ((match_data['team1_id']==team2_id)|(match_data['team2_id']==team2_id))]\\\n",
    "                        .sort_values(by='match_dt', ascending=False).head(n)\n",
    "\n",
    "    df_rel1['bat_inning'] = np.where( ((df_rel1['team1_id']==df_rel1['toss_winner_id'])&(df_rel1['toss_decision']=='bat'))|\\\n",
    "                                            ((df_rel1['team2_id']==df_rel1['toss_winner_id'])&(df_rel1['toss_decision']=='field')) , 1, 2)\n",
    "\n",
    "    df_rel2['bat_inning'] = np.where( ((df_rel2['team1_id']==df_rel2['toss_winner_id'])&(df_rel2['toss_decision']=='bat'))|\\\n",
    "                                            ((df_rel2['team2_id']==df_rel2['toss_winner_id'])&(df_rel2['toss_decision']=='field')) , 1, 2)\n",
    "    \n",
    "    df_rel1 = pd.concat([ df_rel1[df_rel1['bat_inning']==1][['inning1_runs', 'inning1_balls']].rename(columns={'inning1_runs':'runs', 'inning1_balls':'balls'}), \\\n",
    "                         df_rel1[df_rel1['bat_inning']==2][['inning2_runs', 'inning2_balls']].rename(columns={'inning2_runs':'runs', 'inning1_balls':'balls'}) ] )\n",
    "    \n",
    "    df_rel1['RR'] = df_rel1['runs']/df_rel1['balls']\n",
    "    \n",
    "    df_rel2 = pd.concat([ df_rel2[df_rel2['bat_inning']==1][['inning1_runs', 'inning1_balls']].rename(columns={'inning1_runs':'runs', 'inning1_balls':'balls'}), \\\n",
    "                         df_rel2[df_rel2['bat_inning']==2][['inning2_runs', 'inning2_balls']].rename(columns={'inning2_runs':'runs', 'inning1_balls':'balls'}) ] )\n",
    "    \n",
    "    df_rel2['RR'] = df_rel2['runs']/df_rel2['balls']\n",
    "\n",
    "    if len(df_rel1)==0 or len(df_rel2)==0:\n",
    "        return 1\n",
    "    else:\n",
    "        return df_rel1['RR'].mean()/df_rel2['RR'].mean()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Team1 to Team2 ratio features\n",
    "\n",
    "# team1WinpAtGround\n",
    "train_data['team1WinpAtGround'] = train_data.apply(lambda x: \\\n",
    "                                  team1WinpAtGround(x['team1_id'], x['team2_id'], x['match_dt'], x['ground_id']), axis=1)\n",
    "test_data['team1WinpAtGround'] = test_data.apply(lambda x: \\\n",
    "                                  team1WinpAtGround(x['team1_id'], x['team2_id'], x['match_dt'], x['ground_id']), axis=1)\n",
    "\n",
    "# team1WinpLight\n",
    "train_data['team1WinpLight'] = train_data.apply(lambda x: \\\n",
    "                                  team1WinpLight(x['team1_id'], x['team2_id'], x['match_dt'], x['lighting']), axis=1)\n",
    "test_data['team1WinpLight'] = test_data.apply(lambda x: \\\n",
    "                                  team1WinpLight(x['team1_id'], x['team2_id'], x['match_dt'], x['lighting']), axis=1)\n",
    "\n",
    "# team1WinpSeries\n",
    "train_data['team1WinpSeries'] = train_data.apply(lambda x: \\\n",
    "                                  team1WinpSeries(x['team1_id'], x['team2_id'], x['match_dt'], x['series_name']), axis=1)\n",
    "test_data['team1WinpSeries'] = test_data.apply(lambda x: \\\n",
    "                                  team1WinpSeries(x['team1_id'], x['team2_id'], x['match_dt'], x['series_name']), axis=1)\n",
    "\n",
    "# team1AvgRunsMargin\n",
    "train_data['team1AvgRunsMargin'] = train_data.apply(lambda x: \\\n",
    "                                  team1AvgRunsMargin(x['team1_id'], x['team2_id'], x['match_dt'], 15), axis=1)\n",
    "test_data['team1AvgRunsMargin'] = test_data.apply(lambda x: \\\n",
    "                                  team1AvgRunsMargin(x['team1_id'], x['team2_id'], x['match_dt'], 15), axis=1)\n",
    "\n",
    "# team1AvgWicketsMargin\n",
    "train_data['team1AvgWicketsMargin'] = train_data.apply(lambda x: \\\n",
    "                                  team1AvgWicketsMargin(x['team1_id'], x['team2_id'], x['match_dt'], 15), axis=1)\n",
    "test_data['team1AvgWicketsMargin'] = test_data.apply(lambda x: \\\n",
    "                                  team1AvgWicketsMargin(x['team1_id'], x['team2_id'], x['match_dt'], 15), axis=1)\n",
    "\n",
    "# team1AvgWicketsLost\n",
    "train_data['team1AvgWicketsLost'] = train_data.apply(lambda x: \\\n",
    "                                  team1AvgWicketsLost(x['team1_id'], x['team2_id'], x['match_dt'],15), axis=1)\n",
    "test_data['team1AvgWicketsLost'] = test_data.apply(lambda x: \\\n",
    "                                  team1AvgWicketsLost(x['team1_id'], x['team2_id'], x['match_dt'],15), axis=1)\n",
    "\n",
    "# team1AvgRR\n",
    "train_data['team1AvgRR'] = train_data.apply(lambda x: \\\n",
    "                                  team1AvgRR(x['team1_id'], x['team2_id'], x['match_dt'],15), axis=1)\n",
    "test_data['team1AvgRR'] = test_data.apply(lambda x: \\\n",
    "                                  team1AvgRR(x['team1_id'], x['team2_id'], x['match_dt'],15), axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [],
   "source": [
    "cols = ['team_count_50runs_last15', 'team_winp_last5',\n",
    "'team1only_avg_runs_last15', 'team1_winp_team2_last15',\n",
    "'ground_avg_runs_last15', 'tossWinnerWins', 'teamBatsFirstWins',\n",
    "'teamBatsFirstWinsAtGround', 'team1WinpAtGround', 'team1WinpLight',\n",
    "'team1WinpSeries', 'team1AvgRunsMargin','team1AvgWicketsMargin',\n",
    "'team1AvgWicketsLost', 'team1AvgRR']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(None, None)"
      ]
     },
     "execution_count": 138,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data['winner_01'] = train_data.apply(lambda x: 1 if (x['team1_id']==x['winner_id']) else 0, axis=1)\n",
    "train_data.fillna(0, inplace=True), test_data.fillna(0, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data_test = train_data.copy()\n",
    "train_data_test.sort_values(by='match_dt', inplace=True)\n",
    "X_train, y_train, X_test, y_test = train_data_test[cols][:670], train_data_test['winner_01'][:670], train_data_test[cols][670:], train_data_test['winner_01'][670:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # XGBOOST\n",
    "# clf_xgb = xgb.XGBClassifier(booster = 'gbtree', random_state=0, njobs=-1, verbosity=0, eval_metric='error', objective='binary:logistic')\n",
    "# param_xgb = {'n_estimators':[50,100,200,500],\n",
    "#             'learning_rate':[0.01, 0.05, 0.1, 0.2],\n",
    "#             'max_depth':[3,5,7,9]}\n",
    "\n",
    "# gs_xgb = GridSearchCV(clf_xgb, param_xgb, cv=5, n_jobs=-1)\n",
    "# gs_xgb.fit(X_train, y_train)\n",
    "# print(f\"Best parameters are: {gs_xgb.best_params_}\")\n",
    "# y_pred = gs_xgb.predict(X_test)\n",
    "# acc = np.mean(y_pred == y_test)\n",
    "# print(f'Accuracy: {acc}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {},
   "outputs": [],
   "source": [
    "# a = list(zip(cols, gs_xgb.best_estimator_.feature_importances_))\n",
    "# a.sort(key=lambda x: x[1], reverse=True)\n",
    "# pd.DataFrame(a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best parameters are: {'depth': 3, 'learning_rate': 0.01, 'min_data_in_leaf': 10, 'subsample': 0.1}\n",
      "Accuracy: 0.564748201438849\n"
     ]
    }
   ],
   "source": [
    "# CATBOOST\n",
    "clf_cat = cat.CatBoostClassifier(iterations= 100, random_state=0, verbose=0)\n",
    "param_cat = {'learning_rate':[0.01, 0.05, 0.1, 0.2],\n",
    "            'depth':[3,5,7,9],\n",
    "            'subsample':[0.05, 0.1, 0.2, 0.5],\n",
    "            'min_data_in_leaf':[10,40,70,100]}\n",
    "\n",
    "clf_cat = GridSearchCV(clf_cat, param_cat, cv=5, n_jobs=-1)\n",
    "clf_cat.fit(X_train, y_train)\n",
    "print(f\"Best parameters are: {clf_cat.best_params_}\")\n",
    "y_pred = clf_cat.predict(X_test)\n",
    "acc = np.mean(y_pred == y_test)\n",
    "print(f'Accuracy: {acc}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Feature Id</th>\n",
       "      <th>Importances</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>team_count_50runs_last15</td>\n",
       "      <td>29.938779</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>team_winp_last5</td>\n",
       "      <td>13.194991</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>ground_avg_runs_last15</td>\n",
       "      <td>11.115815</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>team1AvgRunsMargin</td>\n",
       "      <td>6.253799</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>team1AvgRR</td>\n",
       "      <td>6.203277</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>tossWinnerWins</td>\n",
       "      <td>5.609025</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>team1AvgWicketsLost</td>\n",
       "      <td>5.084547</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>team1AvgWicketsMargin</td>\n",
       "      <td>4.946626</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>team1only_avg_runs_last15</td>\n",
       "      <td>4.101651</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>team1WinpLight</td>\n",
       "      <td>3.461812</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>teamBatsFirstWins</td>\n",
       "      <td>3.141144</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>teamBatsFirstWinsAtGround</td>\n",
       "      <td>2.496541</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>team1_winp_team2_last15</td>\n",
       "      <td>1.955353</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>team1WinpSeries</td>\n",
       "      <td>1.716188</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>team1WinpAtGround</td>\n",
       "      <td>0.780453</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>team1AvgWicketsLostF2F</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                   Feature Id  Importances\n",
       "0    team_count_50runs_last15    29.938779\n",
       "1             team_winp_last5    13.194991\n",
       "2      ground_avg_runs_last15    11.115815\n",
       "3          team1AvgRunsMargin     6.253799\n",
       "4                  team1AvgRR     6.203277\n",
       "5              tossWinnerWins     5.609025\n",
       "6         team1AvgWicketsLost     5.084547\n",
       "7       team1AvgWicketsMargin     4.946626\n",
       "8   team1only_avg_runs_last15     4.101651\n",
       "9              team1WinpLight     3.461812\n",
       "10          teamBatsFirstWins     3.141144\n",
       "11  teamBatsFirstWinsAtGround     2.496541\n",
       "12    team1_winp_team2_last15     1.955353\n",
       "13            team1WinpSeries     1.716188\n",
       "14          team1WinpAtGround     0.780453\n",
       "15     team1AvgWicketsLostF2F     0.000000"
      ]
     },
     "execution_count": 143,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf_cat.best_estimator_.get_feature_importance(prettified=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # GB\n",
    "# clf_gb = GradientBoostingClassifier(random_state=0)\n",
    "# param_gb = {'learning_rate':[0.01, 0.05, 0.1, 0.2],\n",
    "#             'max_depth':[3,5,7,9],\n",
    "#             'n_estimators':[50,100,200,500],\n",
    "#             'subsample':[0.05, 0.1, 0.2, 0.5],\n",
    "#             'min_samples_split':[2,5,10,15]}\n",
    "\n",
    "# clf_gb = GridSearchCV(clf_gb, param_gb, cv=5, n_jobs=-1)\n",
    "# clf_gb.fit(X_train, y_train)\n",
    "# print(f\"Best parameters are: {clf_gb.best_params_}\")\n",
    "# y_pred = clf_gb.predict(X_test)\n",
    "# acc = np.mean(y_pred == y_test)\n",
    "# print(f'Accuracy: {acc}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {},
   "outputs": [],
   "source": [
    "# feature_importances = clf_gb.best_estimator_.feature_importances_\n",
    "# a = list(zip(cols, feature_importances))\n",
    "# a.sort(key=lambda x: x[1], reverse=True)\n",
    "# a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best parameters are: {'learning_rate': 0.01, 'max_depth': 3, 'min_data_in_leaf': 100}\n",
      "Accuracy: 0.5755395683453237\n"
     ]
    }
   ],
   "source": [
    "# LGB\n",
    "clf_lgb = lgb.LGBMClassifier(random_state=0, verbose=-1, num_leaves = 5)\n",
    "param_lgb = {'learning_rate': [0.01, 0.05, 0.1, 0.2],\n",
    "            'min_data_in_leaf':[10,40,70,100],\n",
    "            'max_depth':[3,5,7,9],}\n",
    "\n",
    "clf_lgb = GridSearchCV(clf_lgb, param_lgb, cv=5, n_jobs=-1)\n",
    "clf_lgb.fit(X_train, y_train)\n",
    "print(f\"Best parameters are: {clf_lgb.best_params_}\")\n",
    "y_pred = clf_lgb.predict(X_test)\n",
    "acc = np.mean(y_pred == y_test)\n",
    "print(f'Accuracy: {acc}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>feat_name</th>\n",
       "      <th>model_feat_imp_train</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>team_count_50runs_last15</td>\n",
       "      <td>95</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>team1AvgRunsMargin</td>\n",
       "      <td>73</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>ground_avg_runs_last15</td>\n",
       "      <td>69</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>team_winp_last5</td>\n",
       "      <td>49</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>team1AvgRR</td>\n",
       "      <td>34</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>team1only_avg_runs_last15</td>\n",
       "      <td>30</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>team1AvgWicketsLost</td>\n",
       "      <td>23</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>team1_winp_team2_last15</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>team1AvgWicketsMargin</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>tossWinnerWins</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>teamBatsFirstWins</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>teamBatsFirstWinsAtGround</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>team1WinpAtGround</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>team1WinpLight</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>team1WinpSeries</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>team1AvgWicketsLostF2F</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                    feat_name  model_feat_imp_train\n",
       "0    team_count_50runs_last15                    95\n",
       "1          team1AvgRunsMargin                    73\n",
       "2      ground_avg_runs_last15                    69\n",
       "3             team_winp_last5                    49\n",
       "4                  team1AvgRR                    34\n",
       "5   team1only_avg_runs_last15                    30\n",
       "6         team1AvgWicketsLost                    23\n",
       "7     team1_winp_team2_last15                     9\n",
       "8       team1AvgWicketsMargin                     7\n",
       "9              tossWinnerWins                     5\n",
       "10          teamBatsFirstWins                     0\n",
       "11  teamBatsFirstWinsAtGround                     0\n",
       "12          team1WinpAtGround                     0\n",
       "13             team1WinpLight                     0\n",
       "14            team1WinpSeries                     0\n",
       "15     team1AvgWicketsLostF2F                     0"
      ]
     },
     "execution_count": 147,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "feature_importances = clf_lgb.best_estimator_.feature_importances_\n",
    "a = list(zip(cols, feature_importances))\n",
    "a.sort(key=lambda x: x[1], reverse=True)\n",
    "feature_importance = pd.DataFrame(a, columns=['feat_name', 'model_feat_imp_train'])\n",
    "feature_importance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Testing the model\n",
    "# train_data_test = train_data.copy()\n",
    "# train_data_test.sort_values(by='match_dt', inplace=True)\n",
    "# X_train, y_train, X_test, y_test = train_data_test[cols][:670], train_data_test['winner_01'][:670], train_data_test[cols][670:], train_data_test['winner_01'][670:]\n",
    "\n",
    "# clf_xgb = gs_xgb.best_estimator_\n",
    "# # clf_cat = clf_cat.best_estimator_\n",
    "# # clf_gb = clf_gb.best_estimator_\n",
    "# clf_lgbm = clf_lgb.best_estimator_\n",
    "\n",
    "# models = {\n",
    "#     'xgb': clf_xgb,\n",
    "#     # 'cat': clf_cat,\n",
    "#     # 'gb' : clf_gb\n",
    "#     'lgbm': clf_lgbm\n",
    "\n",
    "# }\n",
    "\n",
    "# trained_models = [(name, model) for name, model in models.items()]\n",
    "\n",
    "# ensemble = VotingClassifier(estimators=trained_models, voting='soft', verbose=False, n_jobs=-1)\n",
    "# ensemble.fit(X_train, y_train)\n",
    "# y_pred = ensemble.predict(X_test)\n",
    "\n",
    "# acc = np.mean(y_pred == y_test)\n",
    "# print(f'Accuracy for ensemble: {acc}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {},
   "outputs": [],
   "source": [
    "# feature_importance = np.mean(np.array([clf.feature_importances_ for clf in ensemble.estimators_]), axis=0)\n",
    "# a = list(zip(cols, feature_importance))\n",
    "# a.sort(key=lambda x: x[1], reverse=True)\n",
    "# feature_importance = pd.DataFrame(a, columns=['feat_name', 'model_feat_imp_train'])\n",
    "# feature_importance"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Actual"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, y_train, X_test = train_data[cols], train_data['winner_01'], test_data[cols]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 192,
   "metadata": {},
   "outputs": [],
   "source": [
    "# X_train, y_train, X_test = train_data[cols], train_data['winner_01'], test_data[cols]\n",
    "# clf_xgb = gs_xgb.best_estimator_\n",
    "# clf_lgbm = clf_lgb.best_estimator_\n",
    "\n",
    "# models = {\n",
    "#     'xgb': clf_xgb,\n",
    "#     'lgbm': clf_lgbm\n",
    "\n",
    "# }\n",
    "\n",
    "# trained_models = [(name, model) for name, model in models.items()]\n",
    "\n",
    "# ensemble = VotingClassifier(estimators=trained_models, voting='soft', verbose=False, n_jobs=-1)\n",
    "# ensemble.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 191,
   "metadata": {},
   "outputs": [],
   "source": [
    "# feature_importance = np.mean(np.array([clf.feature_importances_ for clf in ensemble.estimators_]), axis=0)\n",
    "# a = list(zip(cols, feature_importance))\n",
    "# a.sort(key=lambda x: x[1], reverse=True)\n",
    "# feature_importance = pd.DataFrame(a, columns=['feat_name', 'model_feat_imp_train'])\n",
    "# feature_importance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best parameters are: {'learning_rate': 0.05, 'max_depth': 5, 'min_data_in_leaf': 100}\n"
     ]
    }
   ],
   "source": [
    "# LGB\n",
    "clf_lgb = lgb.LGBMClassifier(random_state=0, verbose=-1, num_leaves = 5)\n",
    "param_lgb = {'learning_rate': [0.01, 0.05, 0.1, 0.2],\n",
    "            'min_data_in_leaf':[10,40,70,100],\n",
    "            'max_depth':[3,5,7,9],}\n",
    "\n",
    "clf_lgb = GridSearchCV(clf_lgb, param_lgb, cv=5, n_jobs=-1)\n",
    "clf_lgb.fit(X_train, y_train)\n",
    "print(f\"Best parameters are: {clf_lgb.best_params_}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_desc = {'ground_avg_runs_last15':'average runs scored in the ground in last 15 games',\n",
    "                'team_count_50runs_last15':'Ratio of number of 50s by players in team1 to number of 50s by players in team2 in last 15 games',\n",
    "                'team1only_avg_runs_last15':'team1\\'s avg inning runs in last 15 games',\n",
    "                'team_winp_last5':'Ratio of team1\\'s win % to team2\\'s win % in last 5 games',\n",
    "                'tossWinnerWins': 'Ratio of toss winner winning past matches',\n",
    "                'teamBatsFirstWins': 'Ratio of team batting first winning past matches',\n",
    "                'team1WinpSeries': 'Ratio of team1\\'s win % to team2\\'s win % in given series',\n",
    "                'team1_winp_team2_last15':'Team1\\'s win percentage against Team2 in last 15 games',\n",
    "                'team1WinpAtGround': 'iRatio of team1\\'s win % to team2\\'s win % in given ground',\n",
    "                'team1WinpLight': 'Ratio of team1\\'s win % to team2\\'s win % in given lighting',\n",
    "                'team1AvgRunsMargin': 'Ratio of team1\\'s average runs margin to team2\\'s average runs margin in last 15 games',}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_importance = clf_lgb.best_estimator_.feature_importances_\n",
    "a = list(zip(cols, feature_importance))\n",
    "a.sort(key=lambda x: x[1], reverse=True)\n",
    "feature_importance = pd.DataFrame(a, columns=['feat_name', 'model_feat_imp_train']).head(10)\n",
    "feature_importance['model_feat_imp_train'] = feature_importance['model_feat_imp_train']/feature_importance['model_feat_imp_train'].max()\n",
    "feature_importance['feat_description'] = feature_importance['feat_name'].map(feature_desc)\n",
    "feature_importance['feat_id'] = [i+1 for i in feature_importance.index]\n",
    "feature_importance['feat_rank_train'] = [i+1 for i in feature_importance.index]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data['y_pred_01'] = clf_lgb.predict(X_train)\n",
    "test_data['y_pred_01'] = clf_lgb.predict(X_test)\n",
    "\n",
    "train_data['win_pred_score'] = clf_lgb.predict_proba(X_train)[:,1]\n",
    "test_data['win_pred_score'] = clf_lgb.predict_proba(X_test)[:,1]\n",
    "\n",
    "train_data['win_pred_score'] = np.where( (train_data['y_pred_01']==0), (1-train_data['win_pred_score']), train_data['win_pred_score'])\n",
    "test_data['win_pred_score'] = np.where( (test_data['y_pred_01']==0), (1-test_data['win_pred_score']), test_data['win_pred_score'])\n",
    "\n",
    "train_data['win_pred_team_id'] = np.where( (train_data['y_pred_01']==1), (train_data['team1_id']), train_data['team2_id'])\n",
    "test_data['win_pred_team_id'] = np.where( (test_data['y_pred_01']==1), (test_data['team1_id']), test_data['team2_id'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "## refactor\n",
    "train_data['dataset_type'] = 'train'\n",
    "train_data['train_algorithm'] = 'lightgbm'\n",
    "train_data['is_ensemble'] = 'no'\n",
    "train_data['train_hps_trees'] = clf_lgb.best_estimator_.n_estimators_\n",
    "train_data['train_hps_depth'] = clf_lgb.best_estimator_.max_depth\n",
    "train_data['train_hps_lr'] = clf_lgb.best_estimator_.learning_rate\n",
    "train_data['match id'] = train_data['match_id']\n",
    "\n",
    "test_data['dataset_type'] = 'r1'\n",
    "test_data['train_algorithm'] = 'lightgbm'\n",
    "test_data['is_ensemble'] = 'no'\n",
    "test_data['train_hps_trees'] = clf_lgb.best_estimator_.n_estimators_\n",
    "test_data['train_hps_depth'] = clf_lgb.best_estimator_.max_depth\n",
    "test_data['train_hps_lr'] = clf_lgb.best_estimator_.learning_rate\n",
    "test_data['match id'] = test_data['match_id']\n",
    "\n",
    "df_file1 = pd.concat([test_data[['match id','dataset_type','win_pred_team_id','win_pred_score','train_algorithm', 'is_ensemble', 'train_hps_trees', 'train_hps_depth', 'train_hps_lr'] + list(feature_importance['feat_name'].head(10))], \\\n",
    "                     train_data[['match id','dataset_type','win_pred_team_id','win_pred_score','train_algorithm', 'is_ensemble', 'train_hps_trees', 'train_hps_depth', 'train_hps_lr'] + list(feature_importance['feat_name'].head(10))]])\n",
    "\n",
    "renaming_dict = {}\n",
    "for i,col in enumerate(list(feature_importance['feat_name'].head(10))):\n",
    "    renaming_dict[col] = f'indep_feat_id{i+1}'\n",
    "df_file1.rename(columns=renaming_dict, inplace=True)\n",
    "\n",
    "for i in range(1,11):\n",
    "    if f'indep_feat_id{i}' not in df_file1.columns:\n",
    "        df_file1[f'indep_feat_id{i}'] = np.nan"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1219, 19)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_file1.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_file2 = feature_importance[['feat_id', 'feat_name', 'feat_description', 'model_feat_imp_train','feat_rank_train']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(10, 5)"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_file2.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_file1.to_csv('sub/2/primary_submission.csv', index=False)\n",
    "df_file2.to_csv('sub/2/secondary_submission.csv', index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
